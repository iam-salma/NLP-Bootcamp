{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Dataset\n",
    "Context\n",
    "This is a small subset of dataset of Book reviews from Amazon Kindle Store category.\n",
    "\n",
    "Content\n",
    "5-core dataset of product reviews from Amazon Kindle Store category from May 1996 - July 2014. Contains total of 982619 entries. Each reviewer has at least 5 reviews and each product has at least 5 reviews in this dataset.\n",
    "Columns\n",
    "\n",
    "- asin - ID of the product, like B000FA64PK\n",
    "- helpful - helpfulness rating of the review - example: 2/3.\n",
    "- overall - rating of the product.\n",
    "- reviewText - text of the review (heading).\n",
    "- reviewTime - time of the review (raw).\n",
    "- reviewerID - ID of the reviewer, like A3SPTOKDG7WBLN\n",
    "- reviewerName - name of the reviewer.\n",
    "- summary - summary of the review (description).\n",
    "- unixReviewTime - unix timestamp.\n",
    "\n",
    "Acknowledgements\n",
    "This dataset is taken from Amazon product data, Julian McAuley, UCSD website. http://jmcauley.ucsd.edu/data/amazon/\n",
    "\n",
    "License to the data files belong to them.\n",
    "\n",
    "Inspiration\n",
    "- Sentiment analysis on reviews.\n",
    "- Understanding how people rate usefulness of a review/ What factors influence helpfulness of a review.\n",
    "- Fake reviews/ outliers.\n",
    "- Best rated product IDs, or similarity between products based on reviews alone (not the best idea ikr).\n",
    "- Any other interesting analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best Practises\n",
    "1. Preprocessing And Cleaning\n",
    "2. Train Test Split\n",
    "3. BOW,TFIDF,Word2vec\n",
    "4. Train ML algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName                   summary  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley  Entertaining But Average      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler   Terrific menage scenes!      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa          Snapdragon Alley      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace    very light murder cozy      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler                      Book      1356912000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "data=pd.read_csv('../Kindle Reviews/all_kindle_review.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  Jace Rankin may be short, but he's nothing to ...       3\n",
       "1  Great short read.  I didn't want to put it dow...       5\n",
       "2  I'll start by saying this is the first of four...       3\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4  I did not expect this type of book to be in li...       4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data[['reviewText','rating']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Missing Values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    3000\n",
       "4    3000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Preprocessing And Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## postive review is 1 and negative review is 0\n",
    "df['rating']=df['rating'].apply(lambda x:0 if x<3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    8000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. Lower All the cases\n",
    "df['reviewText']=df['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may be short, but he's nothing to ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read.  i didn't want to put it dow...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i'll start by saying this is the first of four...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie is angela lansbury who carries pocketboo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i did not expect this type of book to be in li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may be short, but he's nothing to ...       1\n",
       "1  great short read.  i didn't want to put it dow...       1\n",
       "2  i'll start by saying this is the first of four...       1\n",
       "3  aggie is angela lansbury who carries pocketboo...       1\n",
       "4  i did not expect this type of book to be in li...       1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\salma\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing special characters\n",
    "df['reviewText']=df['reviewText'].apply(lambda x:re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove the stopwords\n",
    "df['reviewText']=df['reviewText'].apply(\n",
    "    lambda x:\" \".join([y for y in x.split() if y not in stopwords.words('english')])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove url\n",
    "df['reviewText']=df['reviewText'].apply(\n",
    "    lambda x: re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(x))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove html tags\n",
    "df['reviewText']=df['reviewText'].apply(lambda x: BeautifulSoup(x, 'lxml').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove any additional spaces\n",
    "df['reviewText']=df['reviewText'].apply(lambda x: \" \".join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize\n",
    "df['reviewText']=df['reviewText'].apply(\n",
    "    lambda x:\" \".join([lemmatizer.lemmatize(word) for word in x.split()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short he nothing mess man haul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sitti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start saying first four book wasnt expecti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carry pocketbook instead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library pleased find price right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may short he nothing mess man haul...       1\n",
       "1  great short read didnt want put read one sitti...       1\n",
       "2  ill start saying first four book wasnt expecti...       1\n",
       "3  aggie angela lansbury carry pocketbook instead...       1\n",
       "4  expect type book library pleased find price right       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(df['reviewText'],df['rating'], test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    BaggingClassifier,\n",
    "    ExtraTreesClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier\n",
    ")\n",
    "\n",
    "classifiers = {\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced', max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=200, class_weight='balanced', random_state=42),\n",
    "    \"SVM\": LinearSVC(class_weight='balanced'),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
    "    \"AdaBoost\": AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "    \"Bagging\": BaggingClassifier(n_estimators=100, random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß† Naive Bayes\n",
      "Accuracy: 0.8329166666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76       825\n",
      "           1       0.88      0.86      0.87      1575\n",
      "\n",
      "    accuracy                           0.83      2400\n",
      "   macro avg       0.81      0.82      0.82      2400\n",
      "weighted avg       0.84      0.83      0.83      2400\n",
      "\n",
      "\n",
      "üß† Logistic Regression\n",
      "Accuracy: 0.8195833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.76      0.74       825\n",
      "           1       0.87      0.85      0.86      1575\n",
      "\n",
      "    accuracy                           0.82      2400\n",
      "   macro avg       0.80      0.81      0.80      2400\n",
      "weighted avg       0.82      0.82      0.82      2400\n",
      "\n",
      "\n",
      "üß† Random Forest\n",
      "Accuracy: 0.80125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.56      0.66       825\n",
      "           1       0.80      0.93      0.86      1575\n",
      "\n",
      "    accuracy                           0.80      2400\n",
      "   macro avg       0.80      0.74      0.76      2400\n",
      "weighted avg       0.80      0.80      0.79      2400\n",
      "\n",
      "\n",
      "üß† SVM\n",
      "Accuracy: 0.78625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69       825\n",
      "           1       0.84      0.84      0.84      1575\n",
      "\n",
      "    accuracy                           0.79      2400\n",
      "   macro avg       0.76      0.76      0.76      2400\n",
      "weighted avg       0.79      0.79      0.79      2400\n",
      "\n",
      "\n",
      "üß† KNN\n",
      "Accuracy: 0.68875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.34      0.43       825\n",
      "           1       0.72      0.87      0.79      1575\n",
      "\n",
      "    accuracy                           0.69      2400\n",
      "   macro avg       0.65      0.61      0.61      2400\n",
      "weighted avg       0.67      0.69      0.66      2400\n",
      "\n",
      "\n",
      "üß† Decision Tree\n",
      "Accuracy: 0.705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58       825\n",
      "           1       0.78      0.77      0.77      1575\n",
      "\n",
      "    accuracy                           0.70      2400\n",
      "   macro avg       0.67      0.68      0.67      2400\n",
      "weighted avg       0.71      0.70      0.71      2400\n",
      "\n",
      "\n",
      "üß† Extra Trees\n",
      "Accuracy: 0.8179166666666666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.61      0.70       825\n",
      "           1       0.82      0.92      0.87      1575\n",
      "\n",
      "    accuracy                           0.82      2400\n",
      "   macro avg       0.82      0.77      0.78      2400\n",
      "weighted avg       0.82      0.82      0.81      2400\n",
      "\n",
      "\n",
      "üß† AdaBoost\n",
      "Accuracy: 0.73625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.35      0.48       825\n",
      "           1       0.73      0.94      0.82      1575\n",
      "\n",
      "    accuracy                           0.74      2400\n",
      "   macro avg       0.74      0.64      0.65      2400\n",
      "weighted avg       0.74      0.74      0.70      2400\n",
      "\n",
      "\n",
      "üß† Bagging\n",
      "Accuracy: 0.7729166666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.59      0.64       825\n",
      "           1       0.80      0.87      0.83      1575\n",
      "\n",
      "    accuracy                           0.77      2400\n",
      "   macro avg       0.75      0.73      0.74      2400\n",
      "weighted avg       0.77      0.77      0.77      2400\n",
      "\n",
      "\n",
      "üß† Gradient Boosting\n",
      "Accuracy: 0.7670833333333333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.41      0.55       825\n",
      "           1       0.76      0.95      0.84      1575\n",
      "\n",
      "    accuracy                           0.77      2400\n",
      "   macro avg       0.79      0.68      0.69      2400\n",
      "weighted avg       0.78      0.77      0.74      2400\n",
      "\n",
      "\n",
      "üß† XGBoost\n",
      "Accuracy: 0.80875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.60      0.68       825\n",
      "           1       0.82      0.92      0.86      1575\n",
      "\n",
      "    accuracy                           0.81      2400\n",
      "   macro avg       0.80      0.76      0.77      2400\n",
      "weighted avg       0.81      0.81      0.80      2400\n",
      "\n",
      "\n",
      "üèÜ Best Model:\n",
      "Naive Bayes with accuracy: 0.8329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "scores = []\n",
    "best_model = None\n",
    "best_score = 0\n",
    "\n",
    "for name, clf in classifiers.items():\n",
    "    print(f\"\\nüß† {name}\")\n",
    "    pipe = Pipeline([\n",
    "        ('cv', CountVectorizer(max_features=3000, stop_words='english', ngram_range=(1, 2))),\n",
    "        ('clf', clf)\n",
    "    ])\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    if acc > best_score:\n",
    "        best_score = acc\n",
    "        best_model = (name, pipe)\n",
    "\n",
    "print(\"\\nüèÜ Best Model:\")\n",
    "print(f\"{best_model[0]} with accuracy: {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Naive Bayes',\n",
       " Pipeline(steps=[('cv',\n",
       "                  CountVectorizer(max_features=3000, ngram_range=(1, 2),\n",
       "                                  stop_words='english')),\n",
       "                 ('clf', MultinomialNB())]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model[1].fit(X_train, y_train)\n",
    "y_pred = best_model[1].predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beautifully written story rich character inspiring message couldnt put']\n",
      "1\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "test_review = \"A beautifully written story with rich characters and an inspiring message ‚Äî I couldn‚Äôt put it down!\"\n",
    "test_review = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", test_review).lower()\n",
    "test_review = \" \".join([word for word in test_review.split() if word not in stopwords.words('english')])\n",
    "test_review=re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(test_review))\n",
    "test_review=BeautifulSoup(test_review, 'lxml').get_text()\n",
    "text_review= \" \".join(test_review.split())\n",
    "test_review=[\" \".join([lemmatizer.lemmatize(word) for word in test_review.split()])]\n",
    "print(test_review)\n",
    "rating = best_model[1].predict(test_review)[0]\n",
    "\n",
    "print(rating)\n",
    "print(\"positive\" if rating == 1 else \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['worst book ive ever readboring repetitive complete waste time']\n",
      "0\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "test_review = \"This was the worst book I‚Äôve ever read‚Äîboring, repetitive, and a complete waste of time.\"\n",
    "test_review = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", test_review).lower()\n",
    "test_review = \" \".join([word for word in test_review.split() if word not in stopwords.words('english')])\n",
    "test_review=re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(test_review))\n",
    "test_review=BeautifulSoup(test_review, 'lxml').get_text()\n",
    "test_review=[\" \".join([lemmatizer.lemmatize(word) for word in test_review.split()])]\n",
    "print(test_review)\n",
    "rating = best_model[1].predict(test_review)[0]\n",
    "\n",
    "print(rating)\n",
    "print(\"positive\" if rating == 1 else \"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow=CountVectorizer()\n",
    "X_train_bow=bow.fit_transform(X_train).toarray()\n",
    "X_test_bow=bow.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf=TfidfVectorizer()\n",
    "X_train_tfidf=tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf=tfidf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model_bow=MultinomialNB().fit(X_train_bow,y_train)\n",
    "model_tfidf=MultinomialNB().fit(X_train_tfidf,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bow=model_bow.predict(X_test_bow)\n",
    "y_pred_tfidf=model_bow.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 544,  281],\n",
       "       [ 121, 1454]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 383,  442],\n",
       "       [  55, 1520]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.66      0.73       825\n",
      "           1       0.84      0.92      0.88      1575\n",
      "\n",
      "    accuracy                           0.83      2400\n",
      "   macro avg       0.83      0.79      0.80      2400\n",
      "weighted avg       0.83      0.83      0.83      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.46      0.61       825\n",
      "           1       0.77      0.97      0.86      1575\n",
      "\n",
      "    accuracy                           0.79      2400\n",
      "   macro avg       0.82      0.71      0.73      2400\n",
      "weighted avg       0.81      0.79      0.77      2400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW accuracy:  0.8325\n",
      "TFIDF accuracy:  0.7929166666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"BOW accuracy: \",accuracy_score(y_test,y_pred_bow))\n",
    "print(\"TFIDF accuracy: \",accuracy_score(y_test,y_pred_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "positive\n"
     ]
    }
   ],
   "source": [
    "test_review = \"A beautifully written story with rich characters and an inspiring message ‚Äî I couldn‚Äôt put it down!\"\n",
    "test_review = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", test_review).lower()\n",
    "test_review = \" \".join([word for word in test_review.split() if word not in stopwords.words('english')])\n",
    "test_review=re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(test_review))\n",
    "test_review=BeautifulSoup(test_review, 'lxml').get_text()\n",
    "text_review= \" \".join(test_review.split())\n",
    "test_review=[\" \".join([lemmatizer.lemmatize(word) for word in test_review.split()])]\n",
    "test_review=bow.transform(test_review).toarray()\n",
    "rating = model_bow.predict(test_review)[0]\n",
    "\n",
    "print(rating)\n",
    "print(\"positive\" if rating == 1 else \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "negative\n"
     ]
    }
   ],
   "source": [
    "test_review = \"This was the worst book I‚Äôve ever read‚Äîboring, repetitive, and a complete waste of time.\"\n",
    "test_review = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", test_review).lower()\n",
    "test_review = \" \".join([word for word in test_review.split() if word not in stopwords.words('english')])\n",
    "test_review=re.sub(r'(http|https|ftp|ssh)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?', '' , str(test_review))\n",
    "test_review=BeautifulSoup(test_review, 'lxml').get_text()\n",
    "text_review= \" \".join(test_review.split())\n",
    "test_review=[\" \".join([lemmatizer.lemmatize(word) for word in test_review.split()])]\n",
    "test_review=bow.transform(test_review).toarray()\n",
    "rating = model_bow.predict(test_review)[0]\n",
    "\n",
    "print(rating)\n",
    "print(\"positive\" if rating == 1 else \"negative\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
